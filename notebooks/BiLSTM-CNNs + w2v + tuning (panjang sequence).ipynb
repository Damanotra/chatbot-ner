{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import talos as ta\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Flatten, Dense, TimeDistributed, \\\n",
    "    SpatialDropout1D, Bidirectional, Conv1D, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConfusionMatrixMetric(tf.keras.metrics.Metric):\n",
    "#     def __init__(self, num_classes, **kwargs):\n",
    "#         super(ConfusionMatrixMetric,self).__init__(name='confusion_matrix_metric',**kwargs)\n",
    "#         self.num_classes=num_classes\n",
    "#         self.total_cm = self.add_weight(\"total\", shape=(num_classes,num_classes), initializer=\"zeros\")\n",
    "        \n",
    "#     def reset_states(self):\n",
    "#         for s in self.variables:\n",
    "#             s.assign(tf.zeros(shape=s.shape))\n",
    "            \n",
    "#     def update_state(self, y_true, y_pred,sample_weight=None):\n",
    "#         self.total_cm.assign_add(self.confusion_matrix(y_true,y_pred))\n",
    "#         return self.total_cm\n",
    "        \n",
    "#     def result(self):\n",
    "#         return self.process_confusion_matrix()\n",
    "    \n",
    "#     def confusion_matrix(self,y_true, y_pred):\n",
    "#         y_pred = tf.argmax(y_pred, axis=2)\n",
    "#         y_true = tf.argmax(y_true, axis=2)\n",
    "\n",
    "#         y_pred = tf.reshape(y_pred, [-1])\n",
    "#         y_true = tf.reshape(y_true, [-1])\n",
    "  \n",
    "#         cm = tf.math.confusion_matrix(\n",
    "#             y_true, \n",
    "#             y_pred, \n",
    "#             dtype=tf.float32, \n",
    "#             num_classes=self.num_classes\n",
    "#         )\n",
    "        \n",
    "#         return cm\n",
    "    \n",
    "#     def process_confusion_matrix(self):\n",
    "#         cm = self.total_cm\n",
    "#         diag_part=tf.linalg.diag_part(cm)\n",
    "#         precision=diag_part/(tf.reduce_sum(cm,0)+tf.constant(1e-15))\n",
    "#         recall=diag_part/(tf.reduce_sum(cm,1)+tf.constant(1e-15))\n",
    "#         f1=2*precision*recall/(precision+recall+tf.constant(1e-15))\n",
    "#         return precision, recall, f1\n",
    "    \n",
    "#     def fill_output(self,output):\n",
    "#         results=self.result()\n",
    "#         for i in range(self.num_classes):\n",
    "#             output['precision_{}'.format(i)]=results[0][i]\n",
    "#             output['recall_{}'.format(i)]=results[1][i]\n",
    "#             output['f1_{}'.format(i)]=results[2][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqModel(tf.keras.Sequential):\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)\n",
    "            loss = self.compiled_loss(\n",
    "                y,\n",
    "                y_pred,\n",
    "                regularization_losses=self.losses,\n",
    "            )\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        output={m.name: m.result() for m in self.metrics[:-1]}\n",
    "        \n",
    "        if 'confusion_matrix_metric' in self.metrics_names:\n",
    "            self.metrics[-1].fill_output(output)\n",
    "\n",
    "        return output\n",
    "        \n",
    "        \n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "\n",
    "        y_pred = self(x, training=False)\n",
    "        loss = self.compiled_loss(\n",
    "            y,\n",
    "            y_pred,\n",
    "            regularization_losses=self.losses,\n",
    "        )\n",
    "\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        output={m.name: m.result() for m in self.metrics[:-1]}\n",
    "        \n",
    "        if 'confusion_matrix_metric' in self.metrics_names:\n",
    "            self.metrics[-1].fill_output(output)    \n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pengamat</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politik</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dari</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Universitas</td>\n",
       "      <td>B-ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gadjah</td>\n",
       "      <td>I-ORGANIZATION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word             tag\n",
       "0     Pengamat               O\n",
       "1      politik               O\n",
       "2         dari               O\n",
       "3  Universitas  B-ORGANIZATION\n",
       "4       Gadjah  I-ORGANIZATION"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>sentence #</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pengamat</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politik</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dari</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Universitas</td>\n",
       "      <td>B-ORGANIZATION</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gadjah</td>\n",
       "      <td>I-ORGANIZATION</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word             tag  sentence #\n",
       "0     Pengamat               O           1\n",
       "1      politik               O           1\n",
       "2         dari               O           1\n",
       "3  Universitas  B-ORGANIZATION           1\n",
       "4       Gadjah  I-ORGANIZATION           1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "cnt = 1\n",
    "\n",
    "for i in df.itertuples():\n",
    "    sentences.append(cnt)\n",
    "    \n",
    "    if '.' in str(i.word):\n",
    "        cnt += 1\n",
    "        \n",
    "df['sentence #'] = sentences\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func = lambda s: [(w, t) for w, t in zip(s['word'].values.tolist(), s['tag'].values.tolist())]\n",
    "grouped = df.groupby('sentence #').apply(agg_func)\n",
    "sentences = [s for s in grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(df['word'].values))\n",
    "words.append('PADDING')\n",
    "num_words = len(words)\n",
    "tags = list(set(df['tag'].values))\n",
    "num_tags = len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate([tag for tag in tags if tag != 'O'])}\n",
    "tag2idx['O'] = len(tags)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'U-QUANTITY': 0,\n",
       " 'U-ORGANIZATION': 1,\n",
       " 'I-ORGANIZATION': 2,\n",
       " 'B-QUANTITY': 3,\n",
       " 'I-TIME': 4,\n",
       " 'L-TIME': 5,\n",
       " 'L-ORGANIZATION': 6,\n",
       " 'B-LOCATION': 7,\n",
       " 'I-QUANTITY': 8,\n",
       " 'B-ORGANIZATION': 9,\n",
       " 'B-TIME': 10,\n",
       " 'I-LOCATION': 11,\n",
       " 'L-PERSON': 12,\n",
       " 'I-PERSON': 13,\n",
       " 'U-TIME': 14,\n",
       " 'U-LOCATION': 15,\n",
       " 'L-LOCATION': 16,\n",
       " 'U-PERSON': 17,\n",
       " 'B-PERSON': 18,\n",
       " 'L-QUANTITY': 19,\n",
       " 'O': 20}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13031"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load(\"../checkpoint/w2vec_wiki_id_case\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(words), 400))\n",
    "\n",
    "for i, w in enumerate(words):\n",
    "    try:\n",
    "        embedding_vector = model.wv[w]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except:\n",
    "        embedding_matrix[i] = np.random.normal(0, np.sqrt(0.25), 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 20\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding='post', value=num_words-1)\n",
    "\n",
    "y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding='post', value=tag2idx['O'])\n",
    "y = [to_categorical(i, num_classes=num_tags) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4892, 20, 21)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_tmp, y_train, y_tmp = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_tmp, y_tmp, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"seq_model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 80, 400)           5212400   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 80, 128)           153728    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_3 (Spatial (None, 80, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 80, 200)           183200    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 80, 21)            4221      \n",
      "=================================================================\n",
      "Total params: 5,553,549\n",
      "Trainable params: 341,149\n",
      "Non-trainable params: 5,212,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = SeqModel([\n",
    "    Input(shape=(max_len, )),\n",
    "    Embedding(\n",
    "        input_dim=embedding_matrix.shape[0], \n",
    "        weights=[embedding_matrix], \n",
    "        output_dim=embedding_matrix.shape[1], \n",
    "        input_length=max_len,\n",
    "        trainable=False\n",
    "    ),\n",
    "    Conv1D(128, 3, activation='relu', padding='same'),\n",
    "    SpatialDropout1D(0.1),\n",
    "    Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1)),\n",
    "    TimeDistributed(Dense(num_tags, activation='softmax'))\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3424 samples, validate on 734 samples\n",
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n"
     ]
    }
   ],
   "source": [
    "f1_score = tfa.metrics.F1Score(\n",
    "    num_classes=num_tags,\n",
    "    average='micro',\n",
    "    name='f1_score',\n",
    "    threshold=0.5\n",
    ")\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=[f1_score, ConfusionMatrixMetric(num_tags)])\n",
    "\n",
    "es=tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, np.array(y_train),\n",
    "    validation_data=(x_val, np.array(y_val)),\n",
    "    epochs=100, verbose=3, callbacks=[es], batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [t for t in tag2idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9827145776566758\n",
      "0.9827145776566758\n",
      "0.9827145776566758\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "actuals = []\n",
    "\n",
    "for i, xt in enumerate(x_val):\n",
    "    p = model.predict(np.array([xt]))\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    y_true = np.argmax(np.array(y_val), axis=-1)[i]\n",
    "    \n",
    "    for true, pred in zip(y_true, p[0]):\n",
    "        actuals.append(true)\n",
    "        preds.append(pred)\n",
    "        \n",
    "print(f1_score(preds, actuals, average='micro'))\n",
    "print(precision_score(preds, actuals, average='micro'))\n",
    "print(recall_score(preds, actuals, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "      I-PERSON       0.64      0.67      0.66        57\n",
      "I-ORGANIZATION       0.65      0.53      0.58       150\n",
      "      U-PERSON       0.85      0.85      0.85       256\n",
      "        B-TIME       0.83      0.52      0.64        48\n",
      "    U-LOCATION       0.78      0.81      0.79       211\n",
      "    L-LOCATION       0.77      0.79      0.78       109\n",
      "L-ORGANIZATION       0.63      0.75      0.69       142\n",
      "    I-QUANTITY       0.56      0.25      0.35        59\n",
      "      B-PERSON       0.85      0.85      0.85       227\n",
      "    I-LOCATION       0.76      0.72      0.74        67\n",
      "    L-QUANTITY       0.55      0.28      0.38        74\n",
      "        U-TIME       0.62      0.25      0.36        20\n",
      "    U-QUANTITY       0.00      0.00      0.00         1\n",
      "    B-LOCATION       0.80      0.75      0.77       109\n",
      "        I-TIME       0.83      0.82      0.83       136\n",
      "B-ORGANIZATION       0.70      0.75      0.72       142\n",
      "        L-TIME       0.78      0.62      0.69        47\n",
      "      L-PERSON       0.87      0.83      0.85       229\n",
      "U-ORGANIZATION       0.71      0.74      0.73       246\n",
      "    B-QUANTITY       0.58      0.37      0.45        76\n",
      "             O       0.99      0.99      0.99     56314\n",
      "\n",
      "      accuracy                           0.98     58720\n",
      "     macro avg       0.70      0.63      0.65     58720\n",
      "  weighted avg       0.98      0.98      0.98     58720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(actuals, preds, target_names=tags, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9315530379661474\n",
      "0.9315530379661474\n",
      "0.9315530379661474\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "actuals = []\n",
    "\n",
    "for i, xt in enumerate(x_val):\n",
    "    p = model.predict(np.array([xt]))\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    y_true = np.argmax(np.array(y_val), axis=-1)[i]\n",
    "    \n",
    "    if 13030 in list(xt):\n",
    "        first_pad_idx = list(xt).index(13030)\n",
    "        _zip = zip(y_true[:first_pad_idx], p[0][:first_pad_idx])\n",
    "    else:\n",
    "        _zip = zip(y_true, p[0])\n",
    "    \n",
    "    for true, pred in _zip:\n",
    "        actuals.append(true)\n",
    "        preds.append(pred)\n",
    "\n",
    "print(f1_score(preds, actuals, average='micro'))\n",
    "print(precision_score(preds, actuals, average='micro'))\n",
    "print(recall_score(preds, actuals, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
