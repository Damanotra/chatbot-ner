{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-ricsMdwIND"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(1)\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import talos as ta\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, \\\n",
    "    SpatialDropout1D, Bidirectional, Conv1D, concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "gNv27H2o0Ejb",
    "outputId": "7a2dc26c-595b-4219-e58d-705d0d9357ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xBYtA960wINN"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "iSXTmmDKwINX",
    "outputId": "5082a340-004d-4fd4-b0b9-fc5c80a7e2b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pengamat</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politik</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dari</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Universitas</td>\n",
       "      <td>B-ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gadjah</td>\n",
       "      <td>I-ORGANIZATION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word             tag\n",
       "0     Pengamat               O\n",
       "1      politik               O\n",
       "2         dari               O\n",
       "3  Universitas  B-ORGANIZATION\n",
       "4       Gadjah  I-ORGANIZATION"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "t87mchhWwINg",
    "outputId": "6fb15da3-1ba8-45ad-bc18-ed06ae1caba0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>sentence #</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pengamat</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politik</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dari</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Universitas</td>\n",
       "      <td>B-ORGANIZATION</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gadjah</td>\n",
       "      <td>I-ORGANIZATION</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word             tag  sentence #\n",
       "0     Pengamat               O           1\n",
       "1      politik               O           1\n",
       "2         dari               O           1\n",
       "3  Universitas  B-ORGANIZATION           1\n",
       "4       Gadjah  I-ORGANIZATION           1"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "cnt = 1\n",
    "\n",
    "for i in df.itertuples():\n",
    "    sentences.append(cnt)\n",
    "    \n",
    "    if '.' in str(i.word):\n",
    "        cnt += 1\n",
    "        \n",
    "df['sentence #'] = sentences\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LclCXTYdwINm"
   },
   "outputs": [],
   "source": [
    "agg_func = lambda s: [(w, t) for w, t in zip(s['word'].values.tolist(), s['tag'].values.tolist())]\n",
    "grouped = df.groupby('sentence #').apply(agg_func)\n",
    "sentences = [s for s in grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v0FezO6xwINs"
   },
   "outputs": [],
   "source": [
    "words = list(set(df['word'].values))\n",
    "words.append('PADDING')\n",
    "num_words = len(words)\n",
    "tags = list(set(df['tag'].values))\n",
    "num_tags = len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XUU3rBgNwINy"
   },
   "outputs": [],
   "source": [
    "tags = sorted([t for t in tags if t != 'O'], key=lambda x: (x[2], x[0]))\n",
    "tags.append('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Ng1XB0nwIN3"
   },
   "outputs": [],
   "source": [
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "id": "U_S5jQ6WwIN7",
    "outputId": "4dbee98b-37e4-4f66-eda8-51ceda19f9c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-LOCATION': 0,\n",
       " 'B-ORGANIZATION': 4,\n",
       " 'B-PERSON': 8,\n",
       " 'B-QUANTITY': 12,\n",
       " 'B-TIME': 16,\n",
       " 'I-LOCATION': 1,\n",
       " 'I-ORGANIZATION': 5,\n",
       " 'I-PERSON': 9,\n",
       " 'I-QUANTITY': 13,\n",
       " 'I-TIME': 17,\n",
       " 'L-LOCATION': 2,\n",
       " 'L-ORGANIZATION': 6,\n",
       " 'L-PERSON': 10,\n",
       " 'L-QUANTITY': 14,\n",
       " 'L-TIME': 18,\n",
       " 'O': 20,\n",
       " 'U-LOCATION': 3,\n",
       " 'U-ORGANIZATION': 7,\n",
       " 'U-PERSON': 11,\n",
       " 'U-QUANTITY': 15,\n",
       " 'U-TIME': 19}"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wB7wOlZ0wIOB"
   },
   "source": [
    "### Pad Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g4nz_7UnwIOC"
   },
   "outputs": [],
   "source": [
    "max_len = 40\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding='post', value=num_words-1)\n",
    "\n",
    "y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding='post', value=tag2idx['O'])\n",
    "y = [to_categorical(i, num_classes=num_tags) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YO6TU5s-wIOG"
   },
   "outputs": [],
   "source": [
    "x_train, x_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val_test, y_val_test, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIdRq0rfwIOL"
   },
   "source": [
    "### Pre-trained Word2Vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q_XsOmLVwIOM"
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load(\"../checkpoint/w2vec_wiki_id_case\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EEKTP6CBwIOR"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(words), 400))\n",
    "\n",
    "for i, w in enumerate(words):\n",
    "    try:\n",
    "        embedding_vector = model.wv[w]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except:\n",
    "        embedding_matrix[i] = np.random.normal(0, np.sqrt(0.25), 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxuWH4t4wIOV"
   },
   "source": [
    "Initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZhcVMn6papG"
   },
   "outputs": [],
   "source": [
    "def f1_score_micro(y_true, y_pred):\n",
    "    y_true = np.argmax(y_true.numpy(), axis=-1).reshape(-1)\n",
    "    y_pred = np.argmax(y_pred.numpy(), axis=-1).reshape(-1)\n",
    "    \n",
    "    # label O will be ignored during training and evaluation\n",
    "    o_pad_idx = np.where(y_true==20) # 20 is the idx for label O\n",
    "    \n",
    "    # remove label O\n",
    "    y_true = np.delete(y_true, o_pad_idx)\n",
    "    y_pred = np.delete(y_pred, o_pad_idx)\n",
    "    \n",
    "    # compute f1 score with micro average\n",
    "    score = f1_score(y_true, y_pred, average='micro')\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7TVjkcxpSel"
   },
   "outputs": [],
   "source": [
    "def create_model(x_train, y_train, x_val, y_val, params):\n",
    "    input_sequence = Input(shape=(max_len, ))\n",
    "    \n",
    "    model = Embedding(\n",
    "        input_dim= embedding_matrix.shape[0], \n",
    "        weights=[embedding_matrix], \n",
    "        output_dim=embedding_matrix.shape[1], \n",
    "        input_length=max_len,\n",
    "        trainable=False\n",
    "    )(input_sequence)\n",
    "    \n",
    "    # dropout layer\n",
    "    model = SpatialDropout1D(params['dropout'])(model)\n",
    "            \n",
    "    # lstm layer\n",
    "    model = Bidirectional(LSTM(units=params['lstm_units'], return_sequences=True))(model)\n",
    "\n",
    "    # convolution layer\n",
    "    model2g = Conv1D(params['filters'], 2, activation='relu', padding='same')(model)\n",
    "    model4g = Conv1D(params['filters'], 4, activation='relu', padding='same')(model)\n",
    "    model6g = Conv1D(params['filters'], 6, activation='relu', padding='same')(model)\n",
    "    model8g = Conv1D(params['filters'], 8, activation='relu', padding='same')(model)\n",
    "    model10g = Conv1D(params['filters'], 10, activation='relu', padding='same')(model)\n",
    "    \n",
    "    model = concatenate([model2g, model4g, model6g, model8g, model10g])\n",
    "    \n",
    "    # output layer\n",
    "    output_sequence = Dense(num_tags, activation='softmax')(model)\n",
    "    \n",
    "    # model\n",
    "    model = Model(input_sequence, output_sequence)\n",
    "    \n",
    "    # learning algorithm (optimizer)\n",
    "    if params['optimizer'] == 'Nadam':\n",
    "        optm = tf.keras.optimizers.Nadam(lr=params['lr'])\n",
    "        \n",
    "    if params['optimizer'] == 'Adam':\n",
    "        optm = tf.keras.optimizers.Adam(lr=params['lr'])\n",
    "        \n",
    "    if params['optimizer'] == 'RMSprop':\n",
    "        optm = tf.keras.optimizers.RMSprop(lr=params['lr'])\n",
    "    \n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optm, metrics=[f1_score_micro], run_eagerly=True)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(patience=10, monitor='val_f1_score_micro', mode='max')\n",
    "\n",
    "    history = model.fit(\n",
    "      x_train, np.array(y_train),\n",
    "      validation_data=(x_val, np.array(y_val)),\n",
    "      epochs=100, verbose=1, callbacks=[early_stopping], batch_size=params['batch_size']\n",
    "    )\n",
    "\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wmYoE6yrwIOW"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'optimizer': ['Adam'],\n",
    "    'lr': [0.01],\n",
    "    'filters': [64],\n",
    "    'lstm_units': [100],\n",
    "    'dropout': [0.1, 0.3, 0.5, 0.7],\n",
    "    'batch_size': [128]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FUNdJv6npSba",
    "outputId": "150a98b5-515b-4453-e270-59d1ae0ea750"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 0.8491 - f1_score_micro: 0.0204 - val_loss: 0.3834 - val_f1_score_micro: 0.0595\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.3041 - f1_score_micro: 0.1789 - val_loss: 0.2398 - val_f1_score_micro: 0.3062\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.1934 - f1_score_micro: 0.4234 - val_loss: 0.1805 - val_f1_score_micro: 0.4592\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.1391 - f1_score_micro: 0.5888 - val_loss: 0.1494 - val_f1_score_micro: 0.5944\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.1101 - f1_score_micro: 0.6819 - val_loss: 0.1370 - val_f1_score_micro: 0.6671\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.0918 - f1_score_micro: 0.7397 - val_loss: 0.1345 - val_f1_score_micro: 0.6654\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.0786 - f1_score_micro: 0.7827 - val_loss: 0.1353 - val_f1_score_micro: 0.6697\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0672 - f1_score_micro: 0.8179 - val_loss: 0.1364 - val_f1_score_micro: 0.6831\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0579 - f1_score_micro: 0.8381 - val_loss: 0.1422 - val_f1_score_micro: 0.7006\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0514 - f1_score_micro: 0.8598 - val_loss: 0.1472 - val_f1_score_micro: 0.6940\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0422 - f1_score_micro: 0.8922 - val_loss: 0.1487 - val_f1_score_micro: 0.7103\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0356 - f1_score_micro: 0.9071 - val_loss: 0.1589 - val_f1_score_micro: 0.6864\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0297 - f1_score_micro: 0.9248 - val_loss: 0.1611 - val_f1_score_micro: 0.6909\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0254 - f1_score_micro: 0.9334 - val_loss: 0.1706 - val_f1_score_micro: 0.6928\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.0232 - f1_score_micro: 0.9432 - val_loss: 0.1692 - val_f1_score_micro: 0.7011\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0190 - f1_score_micro: 0.9516 - val_loss: 0.1872 - val_f1_score_micro: 0.7130\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0168 - f1_score_micro: 0.9597 - val_loss: 0.1974 - val_f1_score_micro: 0.6833\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0140 - f1_score_micro: 0.9650 - val_loss: 0.2003 - val_f1_score_micro: 0.6929\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0114 - f1_score_micro: 0.9755 - val_loss: 0.1997 - val_f1_score_micro: 0.7030\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0088 - f1_score_micro: 0.9795 - val_loss: 0.2048 - val_f1_score_micro: 0.7040\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0079 - f1_score_micro: 0.9831 - val_loss: 0.2138 - val_f1_score_micro: 0.7094\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0065 - f1_score_micro: 0.9872 - val_loss: 0.2166 - val_f1_score_micro: 0.6868\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 0.0062 - f1_score_micro: 0.9883 - val_loss: 0.2249 - val_f1_score_micro: 0.6984\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.0066 - f1_score_micro: 0.9855 - val_loss: 0.2229 - val_f1_score_micro: 0.7050\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0081 - f1_score_micro: 0.9812 - val_loss: 0.2339 - val_f1_score_micro: 0.6941\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.0100 - f1_score_micro: 0.9742 - val_loss: 0.2184 - val_f1_score_micro: 0.7154\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0111 - f1_score_micro: 0.9749 - val_loss: 0.2194 - val_f1_score_micro: 0.7174\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0101 - f1_score_micro: 0.9777 - val_loss: 0.2419 - val_f1_score_micro: 0.6763\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0104 - f1_score_micro: 0.9763 - val_loss: 0.2241 - val_f1_score_micro: 0.7046\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0078 - f1_score_micro: 0.9824 - val_loss: 0.2294 - val_f1_score_micro: 0.7105\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0063 - f1_score_micro: 0.9865 - val_loss: 0.2337 - val_f1_score_micro: 0.6953\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0047 - f1_score_micro: 0.9911 - val_loss: 0.2312 - val_f1_score_micro: 0.6999\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 0.0036 - f1_score_micro: 0.9935 - val_loss: 0.2408 - val_f1_score_micro: 0.6878\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0029 - f1_score_micro: 0.9956 - val_loss: 0.2401 - val_f1_score_micro: 0.7108\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0026 - f1_score_micro: 0.9961 - val_loss: 0.2468 - val_f1_score_micro: 0.6999\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0023 - f1_score_micro: 0.9968 - val_loss: 0.2477 - val_f1_score_micro: 0.7271\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0020 - f1_score_micro: 0.9975 - val_loss: 0.2504 - val_f1_score_micro: 0.7276\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0023 - f1_score_micro: 0.9966 - val_loss: 0.2581 - val_f1_score_micro: 0.7046\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0022 - f1_score_micro: 0.9964 - val_loss: 0.2531 - val_f1_score_micro: 0.7064\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0022 - f1_score_micro: 0.9975 - val_loss: 0.2537 - val_f1_score_micro: 0.7237\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0021 - f1_score_micro: 0.9974 - val_loss: 0.2548 - val_f1_score_micro: 0.7160\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0020 - f1_score_micro: 0.9969 - val_loss: 0.2605 - val_f1_score_micro: 0.7307\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0021 - f1_score_micro: 0.9974 - val_loss: 0.2618 - val_f1_score_micro: 0.7101\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0020 - f1_score_micro: 0.9968 - val_loss: 0.2712 - val_f1_score_micro: 0.7190\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0024 - f1_score_micro: 0.9956 - val_loss: 0.2667 - val_f1_score_micro: 0.6925\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0028 - f1_score_micro: 0.9951 - val_loss: 0.2633 - val_f1_score_micro: 0.7135\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.0025 - f1_score_micro: 0.9956 - val_loss: 0.2639 - val_f1_score_micro: 0.6965\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.0025 - f1_score_micro: 0.9957 - val_loss: 0.2689 - val_f1_score_micro: 0.7027\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0034 - f1_score_micro: 0.9932 - val_loss: 0.2720 - val_f1_score_micro: 0.6938\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0037 - f1_score_micro: 0.9929 - val_loss: 0.2742 - val_f1_score_micro: 0.6906\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0057 - f1_score_micro: 0.9870 - val_loss: 0.2622 - val_f1_score_micro: 0.7248\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0060 - f1_score_micro: 0.9862 - val_loss: 0.2708 - val_f1_score_micro: 0.7021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 1/4 [01:07<03:22, 67.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 1.3878 - f1_score_micro: 0.0015 - val_loss: 1.3077 - val_f1_score_micro: 0.0000e+00\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 1.3375 - f1_score_micro: 0.0015 - val_loss: 1.2841 - val_f1_score_micro: 0.0399\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.9506 - f1_score_micro: 0.0141 - val_loss: 0.4169 - val_f1_score_micro: 0.0328\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.3506 - f1_score_micro: 0.0588 - val_loss: 0.2932 - val_f1_score_micro: 0.1204\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.2504 - f1_score_micro: 0.2517 - val_loss: 0.2207 - val_f1_score_micro: 0.3129\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.1965 - f1_score_micro: 0.3863 - val_loss: 0.1880 - val_f1_score_micro: 0.4007\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.1598 - f1_score_micro: 0.4998 - val_loss: 0.1543 - val_f1_score_micro: 0.5501\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.1344 - f1_score_micro: 0.5978 - val_loss: 0.1431 - val_f1_score_micro: 0.5424\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.1187 - f1_score_micro: 0.6484 - val_loss: 0.1308 - val_f1_score_micro: 0.6640\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.1070 - f1_score_micro: 0.6912 - val_loss: 0.1277 - val_f1_score_micro: 0.6912\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0974 - f1_score_micro: 0.7254 - val_loss: 0.1216 - val_f1_score_micro: 0.6864\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0895 - f1_score_micro: 0.7440 - val_loss: 0.1235 - val_f1_score_micro: 0.6971\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.0852 - f1_score_micro: 0.7630 - val_loss: 0.1210 - val_f1_score_micro: 0.7525\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0782 - f1_score_micro: 0.7845 - val_loss: 0.1183 - val_f1_score_micro: 0.6988\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0709 - f1_score_micro: 0.8039 - val_loss: 0.1219 - val_f1_score_micro: 0.7272\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 0.0667 - f1_score_micro: 0.8130 - val_loss: 0.1213 - val_f1_score_micro: 0.7311\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0624 - f1_score_micro: 0.8331 - val_loss: 0.1204 - val_f1_score_micro: 0.7179\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0574 - f1_score_micro: 0.8408 - val_loss: 0.1284 - val_f1_score_micro: 0.7023\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0570 - f1_score_micro: 0.8440 - val_loss: 0.1360 - val_f1_score_micro: 0.7115\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0530 - f1_score_micro: 0.8522 - val_loss: 0.1316 - val_f1_score_micro: 0.7523\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0468 - f1_score_micro: 0.8758 - val_loss: 0.1282 - val_f1_score_micro: 0.7354\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.0417 - f1_score_micro: 0.8891 - val_loss: 0.1380 - val_f1_score_micro: 0.7521\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0408 - f1_score_micro: 0.8919 - val_loss: 0.1360 - val_f1_score_micro: 0.7361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 2/4 [01:37<01:52, 56.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 0.6476 - f1_score_micro: 0.0109 - val_loss: 0.3484 - val_f1_score_micro: 0.0420\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.3086 - f1_score_micro: 0.1095 - val_loss: 0.2478 - val_f1_score_micro: 0.2707\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.2192 - f1_score_micro: 0.3425 - val_loss: 0.1853 - val_f1_score_micro: 0.4390\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.1714 - f1_score_micro: 0.4860 - val_loss: 0.1550 - val_f1_score_micro: 0.5332\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.1472 - f1_score_micro: 0.5651 - val_loss: 0.1418 - val_f1_score_micro: 0.6452\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 0.1282 - f1_score_micro: 0.6262 - val_loss: 0.1272 - val_f1_score_micro: 0.6513\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.1176 - f1_score_micro: 0.6636 - val_loss: 0.1306 - val_f1_score_micro: 0.7182\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.1064 - f1_score_micro: 0.6926 - val_loss: 0.1247 - val_f1_score_micro: 0.7188\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.0970 - f1_score_micro: 0.7237 - val_loss: 0.1257 - val_f1_score_micro: 0.6735\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0905 - f1_score_micro: 0.7384 - val_loss: 0.1146 - val_f1_score_micro: 0.7017\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0838 - f1_score_micro: 0.7538 - val_loss: 0.1229 - val_f1_score_micro: 0.7333\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0780 - f1_score_micro: 0.7815 - val_loss: 0.1242 - val_f1_score_micro: 0.7393\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0718 - f1_score_micro: 0.7937 - val_loss: 0.1186 - val_f1_score_micro: 0.7326\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0679 - f1_score_micro: 0.8098 - val_loss: 0.1187 - val_f1_score_micro: 0.7376\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0626 - f1_score_micro: 0.8221 - val_loss: 0.1180 - val_f1_score_micro: 0.7581\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0593 - f1_score_micro: 0.8424 - val_loss: 0.1322 - val_f1_score_micro: 0.7089\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0555 - f1_score_micro: 0.8413 - val_loss: 0.1285 - val_f1_score_micro: 0.7007\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0518 - f1_score_micro: 0.8548 - val_loss: 0.1331 - val_f1_score_micro: 0.7330\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0473 - f1_score_micro: 0.8690 - val_loss: 0.1285 - val_f1_score_micro: 0.7346\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0444 - f1_score_micro: 0.8732 - val_loss: 0.1384 - val_f1_score_micro: 0.7362\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0448 - f1_score_micro: 0.8745 - val_loss: 0.1362 - val_f1_score_micro: 0.7307\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0396 - f1_score_micro: 0.8858 - val_loss: 0.1410 - val_f1_score_micro: 0.7318\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0370 - f1_score_micro: 0.8984 - val_loss: 0.1403 - val_f1_score_micro: 0.7295\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0359 - f1_score_micro: 0.9010 - val_loss: 0.1396 - val_f1_score_micro: 0.7211\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0336 - f1_score_micro: 0.9076 - val_loss: 0.1442 - val_f1_score_micro: 0.7246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 3/4 [02:10<00:49, 49.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.6548 - f1_score_micro: 0.0098 - val_loss: 0.3439 - val_f1_score_micro: 0.0700\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.3064 - f1_score_micro: 0.1125 - val_loss: 0.2442 - val_f1_score_micro: 0.2805\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.2268 - f1_score_micro: 0.3367 - val_loss: 0.1880 - val_f1_score_micro: 0.4296\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.1883 - f1_score_micro: 0.4413 - val_loss: 0.1586 - val_f1_score_micro: 0.4944\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.1661 - f1_score_micro: 0.5040 - val_loss: 0.1468 - val_f1_score_micro: 0.5980\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.1502 - f1_score_micro: 0.5524 - val_loss: 0.1410 - val_f1_score_micro: 0.6792\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.1367 - f1_score_micro: 0.6032 - val_loss: 0.1295 - val_f1_score_micro: 0.6343\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.1288 - f1_score_micro: 0.6228 - val_loss: 0.1209 - val_f1_score_micro: 0.6866\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.1210 - f1_score_micro: 0.6498 - val_loss: 0.1171 - val_f1_score_micro: 0.6623\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.1160 - f1_score_micro: 0.6560 - val_loss: 0.1193 - val_f1_score_micro: 0.6723\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.1114 - f1_score_micro: 0.6724 - val_loss: 0.1153 - val_f1_score_micro: 0.6495\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.1027 - f1_score_micro: 0.7043 - val_loss: 0.1094 - val_f1_score_micro: 0.7097\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0971 - f1_score_micro: 0.7179 - val_loss: 0.1105 - val_f1_score_micro: 0.6939\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0918 - f1_score_micro: 0.7307 - val_loss: 0.1130 - val_f1_score_micro: 0.7568\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0908 - f1_score_micro: 0.7411 - val_loss: 0.1120 - val_f1_score_micro: 0.7214\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 0.0858 - f1_score_micro: 0.7541 - val_loss: 0.1113 - val_f1_score_micro: 0.7503\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 0.0815 - f1_score_micro: 0.7643 - val_loss: 0.1164 - val_f1_score_micro: 0.7546\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0785 - f1_score_micro: 0.7715 - val_loss: 0.1141 - val_f1_score_micro: 0.7278\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0773 - f1_score_micro: 0.7777 - val_loss: 0.1149 - val_f1_score_micro: 0.7277\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0743 - f1_score_micro: 0.7863 - val_loss: 0.1113 - val_f1_score_micro: 0.7496\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0703 - f1_score_micro: 0.8009 - val_loss: 0.1250 - val_f1_score_micro: 0.7389\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 0.0670 - f1_score_micro: 0.8096 - val_loss: 0.1230 - val_f1_score_micro: 0.7416\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 0.0649 - f1_score_micro: 0.8110 - val_loss: 0.1196 - val_f1_score_micro: 0.7653\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0634 - f1_score_micro: 0.8191 - val_loss: 0.1243 - val_f1_score_micro: 0.7493\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0618 - f1_score_micro: 0.8212 - val_loss: 0.1267 - val_f1_score_micro: 0.7514\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.0596 - f1_score_micro: 0.8282 - val_loss: 0.1302 - val_f1_score_micro: 0.7433\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0572 - f1_score_micro: 0.8416 - val_loss: 0.1251 - val_f1_score_micro: 0.7312\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0554 - f1_score_micro: 0.8450 - val_loss: 0.1328 - val_f1_score_micro: 0.7521\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0536 - f1_score_micro: 0.8549 - val_loss: 0.1319 - val_f1_score_micro: 0.7648\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0517 - f1_score_micro: 0.8562 - val_loss: 0.1322 - val_f1_score_micro: 0.7479\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0495 - f1_score_micro: 0.8600 - val_loss: 0.1284 - val_f1_score_micro: 0.7523\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.0487 - f1_score_micro: 0.8634 - val_loss: 0.1360 - val_f1_score_micro: 0.7369\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0480 - f1_score_micro: 0.8634 - val_loss: 0.1380 - val_f1_score_micro: 0.7635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [02:53<00:00, 43.44s/it]\n"
     ]
    }
   ],
   "source": [
    "t = ta.Scan(x=x_train,\n",
    "    y=np.array(y_train),\n",
    "    x_val=x_val,\n",
    "    y_val=np.array(y_val),\n",
    "    model=create_model,\n",
    "    params=params,\n",
    "    experiment_name='bilstm_cnns_w2v_opt_v3', \n",
    "    val_split=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ecnGwoOCwzxz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQOsOIlPwzp-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "HEHUe169vuus",
    "outputId": "11b503d8-5d84-467a-ff0a-587287cba327"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>f1_score_micro</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_f1_score_micro</th>\n",
       "      <th>dropout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.048002</td>\n",
       "      <td>0.863403</td>\n",
       "      <td>0.137955</td>\n",
       "      <td>0.763460</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.040812</td>\n",
       "      <td>0.891935</td>\n",
       "      <td>0.135959</td>\n",
       "      <td>0.736122</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.033616</td>\n",
       "      <td>0.907585</td>\n",
       "      <td>0.144163</td>\n",
       "      <td>0.724609</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006004</td>\n",
       "      <td>0.986169</td>\n",
       "      <td>0.270796</td>\n",
       "      <td>0.702142</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  f1_score_micro  val_loss  val_f1_score_micro  dropout\n",
       "3  0.048002        0.863403  0.137955            0.763460      0.7\n",
       "1  0.040812        0.891935  0.135959            0.736122      0.3\n",
       "2  0.033616        0.907585  0.144163            0.724609      0.5\n",
       "0  0.006004        0.986169  0.270796            0.702142      0.1"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# round 4\n",
    "t.data[['loss', 'f1_score_micro', 'val_loss', 'val_f1_score_micro', 'dropout']] \\\n",
    "    .sort_values(by=['val_f1_score_micro'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9cjiAmF351OS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AuWRYned51LS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "iLAhH3A55zxz",
    "outputId": "6c87f985-83e0-48f4-94fe-838021a101f6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>f1_score_micro</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_f1_score_micro</th>\n",
       "      <th>filters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021418</td>\n",
       "      <td>0.942006</td>\n",
       "      <td>0.165591</td>\n",
       "      <td>0.732211</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016788</td>\n",
       "      <td>0.954940</td>\n",
       "      <td>0.182246</td>\n",
       "      <td>0.724843</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.034370</td>\n",
       "      <td>0.907809</td>\n",
       "      <td>0.139293</td>\n",
       "      <td>0.712943</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.342312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.307674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  f1_score_micro  val_loss  val_f1_score_micro  filters\n",
       "1  0.021418        0.942006  0.165591            0.732211       64\n",
       "0  0.016788        0.954940  0.182246            0.724843       32\n",
       "2  0.034370        0.907809  0.139293            0.712943      128\n",
       "3  1.342312        0.000000  1.307674            0.000000      256"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# round 3\n",
    "t.data[['loss', 'f1_score_micro', 'val_loss', 'val_f1_score_micro', 'filters']] \\\n",
    "    .sort_values(by=['val_f1_score_micro'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mZv2txoE5zuk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i7iI0TPZvur7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "Ciky0emxuq8E",
    "outputId": "dfcee5d4-af94-4a14-e08a-aba150c77159"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>f1_score_micro</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_f1_score_micro</th>\n",
       "      <th>lstm_units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023470</td>\n",
       "      <td>0.936328</td>\n",
       "      <td>0.154423</td>\n",
       "      <td>0.743864</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018684</td>\n",
       "      <td>0.951146</td>\n",
       "      <td>0.180076</td>\n",
       "      <td>0.721642</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.024138</td>\n",
       "      <td>0.935081</td>\n",
       "      <td>0.160149</td>\n",
       "      <td>0.715991</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  f1_score_micro  val_loss  val_f1_score_micro  lstm_units\n",
       "1  0.023470        0.936328  0.154423            0.743864         100\n",
       "0  0.018684        0.951146  0.180076            0.721642          50\n",
       "2  0.024138        0.935081  0.160149            0.715991         200"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# round 2\n",
    "t.data[['loss', 'f1_score_micro', 'val_loss', 'val_f1_score_micro', 'lstm_units']] \\\n",
    "    .sort_values(by=['val_f1_score_micro'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "idy1gUy9vD7N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "wxkQSkcipSZB",
    "outputId": "f07d00c7-4261-49e8-b996-5a73fd7ff12d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>f1_score_micro</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_f1_score_micro</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.033131</td>\n",
       "      <td>0.909018</td>\n",
       "      <td>0.155255</td>\n",
       "      <td>0.749481</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018617</td>\n",
       "      <td>0.959671</td>\n",
       "      <td>0.242784</td>\n",
       "      <td>0.725582</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014270</td>\n",
       "      <td>0.961801</td>\n",
       "      <td>0.200763</td>\n",
       "      <td>0.722709</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.053579</td>\n",
       "      <td>0.844449</td>\n",
       "      <td>0.143233</td>\n",
       "      <td>0.680638</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.052520</td>\n",
       "      <td>0.849761</td>\n",
       "      <td>0.139515</td>\n",
       "      <td>0.665578</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.062011</td>\n",
       "      <td>0.819389</td>\n",
       "      <td>0.136630</td>\n",
       "      <td>0.652294</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.128877</td>\n",
       "      <td>0.603348</td>\n",
       "      <td>0.149714</td>\n",
       "      <td>0.567691</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.138077</td>\n",
       "      <td>0.576162</td>\n",
       "      <td>0.153528</td>\n",
       "      <td>0.530675</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.140273</td>\n",
       "      <td>0.570369</td>\n",
       "      <td>0.157246</td>\n",
       "      <td>0.529732</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  f1_score_micro  val_loss  val_f1_score_micro optimizer      lr\n",
       "1  0.033131        0.909018  0.155255            0.749481      Adam  0.0100\n",
       "2  0.018617        0.959671  0.242784            0.725582   RMSprop  0.0100\n",
       "0  0.014270        0.961801  0.200763            0.722709     Nadam  0.0100\n",
       "4  0.053579        0.844449  0.143233            0.680638      Adam  0.0010\n",
       "3  0.052520        0.849761  0.139515            0.665578     Nadam  0.0010\n",
       "5  0.062011        0.819389  0.136630            0.652294   RMSprop  0.0010\n",
       "8  0.128877        0.603348  0.149714            0.567691   RMSprop  0.0001\n",
       "7  0.138077        0.576162  0.153528            0.530675      Adam  0.0001\n",
       "6  0.140273        0.570369  0.157246            0.529732     Nadam  0.0001"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# round 1\n",
    "t.data[['loss', 'f1_score_micro', 'val_loss', 'val_f1_score_micro', 'optimizer', 'lr']] \\\n",
    "    .sort_values(by=['val_f1_score_micro'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hHwMTvmApSWs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hyper-parameter tuning BiLSTM-CNNs + multi-sequence n-gram + w2v",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
