{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Flatten, Dense, TimeDistributed, \\\n",
    "    SpatialDropout1D, Bidirectional, Conv1D, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D, \\\n",
    "    Concatenate, concatenate\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConfusionMatrixMetric(tf.keras.metrics.Metric):\n",
    "#     def __init__(self, num_classes, **kwargs):\n",
    "#         super(ConfusionMatrixMetric,self).__init__(name='confusion_matrix_metric',**kwargs)\n",
    "#         self.num_classes=num_classes\n",
    "#         self.total_cm = self.add_weight(\"total\", shape=(num_classes,num_classes), initializer=\"zeros\")\n",
    "        \n",
    "#     def reset_states(self):\n",
    "#         for s in self.variables:\n",
    "#             s.assign(tf.zeros(shape=s.shape))\n",
    "            \n",
    "#     def update_state(self, y_true, y_pred,sample_weight=None):\n",
    "#         self.total_cm.assign_add(self.confusion_matrix(y_true,y_pred))\n",
    "#         return self.total_cm\n",
    "        \n",
    "#     def result(self):\n",
    "#         return self.process_confusion_matrix()\n",
    "    \n",
    "#     def confusion_matrix(self,y_true, y_pred):\n",
    "#         y_pred = tf.argmax(y_pred, axis=2)\n",
    "#         y_true = tf.argmax(y_true, axis=2)\n",
    "\n",
    "#         y_pred = tf.reshape(y_pred, [-1])\n",
    "#         y_true = tf.reshape(y_true, [-1])\n",
    "  \n",
    "#         cm = tf.math.confusion_matrix(\n",
    "#             y_true, \n",
    "#             y_pred, \n",
    "#             dtype=tf.float32, \n",
    "#             num_classes=self.num_classes\n",
    "#         )\n",
    "        \n",
    "#         return cm\n",
    "    \n",
    "#     def process_confusion_matrix(self):\n",
    "#         cm = self.total_cm\n",
    "#         diag_part=tf.linalg.diag_part(cm)\n",
    "#         precision=diag_part/(tf.reduce_sum(cm,0)+tf.constant(1e-15))\n",
    "#         recall=diag_part/(tf.reduce_sum(cm,1)+tf.constant(1e-15))\n",
    "#         f1=2*precision*recall/(precision+recall+tf.constant(1e-15))\n",
    "#         return precision, recall, f1\n",
    "    \n",
    "#     def fill_output(self,output):\n",
    "#         results=self.result()\n",
    "#         for i in range(self.num_classes):\n",
    "#             output['precision_{}'.format(i)]=results[0][i]\n",
    "#             output['recall_{}'.format(i)]=results[1][i]\n",
    "#             output['f1_{}'.format(i)]=results[2][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pengamat</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politik</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dari</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Universitas</td>\n",
       "      <td>B-ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gadjah</td>\n",
       "      <td>I-ORGANIZATION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word             tag\n",
       "0     Pengamat               O\n",
       "1      politik               O\n",
       "2         dari               O\n",
       "3  Universitas  B-ORGANIZATION\n",
       "4       Gadjah  I-ORGANIZATION"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>sentence #</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pengamat</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politik</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dari</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Universitas</td>\n",
       "      <td>B-ORGANIZATION</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gadjah</td>\n",
       "      <td>I-ORGANIZATION</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word             tag  sentence #\n",
       "0     Pengamat               O           1\n",
       "1      politik               O           1\n",
       "2         dari               O           1\n",
       "3  Universitas  B-ORGANIZATION           1\n",
       "4       Gadjah  I-ORGANIZATION           1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "cnt = 1\n",
    "\n",
    "for i in df.itertuples():\n",
    "    sentences.append(cnt)\n",
    "    \n",
    "    if '.' in str(i.word):\n",
    "        cnt += 1\n",
    "        \n",
    "df['sentence #'] = sentences\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func = lambda s: [(w, t) for w, t in zip(s['word'].values.tolist(), s['tag'].values.tolist())]\n",
    "grouped = df.groupby('sentence #').apply(agg_func)\n",
    "sentences = [s for s in grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(df['word'].values))\n",
    "words.append('PADDING')\n",
    "num_words = len(words)\n",
    "tags = list(set(df['tag'].values))\n",
    "num_tags = len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate([tag for tag in tags if tag != 'O'])}\n",
    "tag2idx['O'] = len(tags)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-LOCATION': 0,\n",
       " 'L-PERSON': 1,\n",
       " 'U-TIME': 2,\n",
       " 'B-ORGANIZATION': 3,\n",
       " 'I-PERSON': 4,\n",
       " 'L-ORGANIZATION': 5,\n",
       " 'L-TIME': 6,\n",
       " 'B-QUANTITY': 7,\n",
       " 'I-ORGANIZATION': 8,\n",
       " 'B-PERSON': 9,\n",
       " 'B-TIME': 10,\n",
       " 'U-ORGANIZATION': 11,\n",
       " 'U-PERSON': 12,\n",
       " 'I-QUANTITY': 13,\n",
       " 'I-LOCATION': 14,\n",
       " 'U-LOCATION': 15,\n",
       " 'L-QUANTITY': 16,\n",
       " 'U-QUANTITY': 17,\n",
       " 'L-LOCATION': 18,\n",
       " 'I-TIME': 19,\n",
       " 'O': 20}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 80\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding='post', value=num_words-1)\n",
    "\n",
    "y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding='post', value=tag2idx['O'])\n",
    "y = [to_categorical(i, num_classes=num_tags) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load(\"../checkpoint/w2vec_wiki_id_case\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(words), 400))\n",
    "\n",
    "for i, w in enumerate(words):\n",
    "    try:\n",
    "        embedding_vector = model.wv[w]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except:\n",
    "        embedding_matrix[i] = np.random.normal(0, np.sqrt(0.25), 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13031, 400)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 80)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 80, 400)      5212400     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 80, 400)      0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 80, 128)      102528      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 80, 128)      204928      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 80, 128)      307328      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 80, 128)      409728      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 80, 128)      512128      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 80, 640)      0           conv1d_15[0][0]                  \n",
      "                                                                 conv1d_16[0][0]                  \n",
      "                                                                 conv1d_17[0][0]                  \n",
      "                                                                 conv1d_18[0][0]                  \n",
      "                                                                 conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 80, 200)      592800      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 80, 21)       4221        bidirectional_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 7,346,061\n",
      "Trainable params: 2,133,661\n",
      "Non-trainable params: 5,212,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_sequence = Input(shape=(max_len, ))\n",
    "model = Embedding(\n",
    "    input_dim=embedding_matrix.shape[0], \n",
    "    weights=[embedding_matrix], \n",
    "    output_dim=embedding_matrix.shape[1], \n",
    "    input_length=max_len,\n",
    "    trainable=False\n",
    ")(input_sequence)\n",
    "model = SpatialDropout1D(0.5)(model)\n",
    "model2g = Conv1D(128, 2, activation='relu', padding='same')(model)\n",
    "model4g = Conv1D(128, 4, activation='relu', padding='same')(model)\n",
    "model6g = Conv1D(128, 6, activation='relu', padding='same')(model)\n",
    "model8g = Conv1D(128, 8, activation='relu', padding='same')(model)\n",
    "model10g = Conv1D(128, 10, activation='relu', padding='same')(model)\n",
    "model = concatenate([model2g, model4g, model6g, model8g, model10g])\n",
    "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.5))(model)\n",
    "output_sequence = Dense(num_tags, activation='softmax')(model)\n",
    "model = Model(input_sequence, output_sequence)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = tfa.metrics.F1Score(\n",
    "    num_classes=num_tags,\n",
    "    average='micro',\n",
    "    name='f1_score',\n",
    "    threshold=0.5\n",
    ")\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=[f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3424 samples, validate on 734 samples\n",
      "Epoch 1/100\n",
      "3424/3424 [==============================] - 33s 10ms/sample - loss: 0.3062 - f1_score: 0.9459 - val_loss: 0.2027 - val_f1_score: 0.9594\n",
      "Epoch 2/100\n",
      "3424/3424 [==============================] - 36s 11ms/sample - loss: 0.1923 - f1_score: 0.9592 - val_loss: 0.1704 - val_f1_score: 0.9627\n",
      "Epoch 3/100\n",
      "3424/3424 [==============================] - 34s 10ms/sample - loss: 0.1608 - f1_score: 0.9627 - val_loss: 0.1451 - val_f1_score: 0.9654\n",
      "Epoch 4/100\n",
      "3424/3424 [==============================] - 33s 10ms/sample - loss: 0.1400 - f1_score: 0.9655 - val_loss: 0.1278 - val_f1_score: 0.9676\n",
      "Epoch 5/100\n",
      "3424/3424 [==============================] - 34s 10ms/sample - loss: 0.1244 - f1_score: 0.9674 - val_loss: 0.1141 - val_f1_score: 0.9703\n",
      "Epoch 6/100\n",
      "3424/3424 [==============================] - 33s 10ms/sample - loss: 0.1109 - f1_score: 0.9696 - val_loss: 0.1018 - val_f1_score: 0.9724\n",
      "Epoch 7/100\n",
      "3424/3424 [==============================] - 32s 9ms/sample - loss: 0.0998 - f1_score: 0.9718 - val_loss: 0.0935 - val_f1_score: 0.9735\n",
      "Epoch 8/100\n",
      "3424/3424 [==============================] - 34s 10ms/sample - loss: 0.0911 - f1_score: 0.9736 - val_loss: 0.0866 - val_f1_score: 0.9750\n",
      "Epoch 9/100\n",
      "3424/3424 [==============================] - 36s 11ms/sample - loss: 0.0845 - f1_score: 0.9748 - val_loss: 0.0819 - val_f1_score: 0.9761\n",
      "Epoch 10/100\n",
      "3424/3424 [==============================] - 35s 10ms/sample - loss: 0.0780 - f1_score: 0.9764 - val_loss: 0.0773 - val_f1_score: 0.9765\n",
      "Epoch 11/100\n",
      "3424/3424 [==============================] - 34s 10ms/sample - loss: 0.0738 - f1_score: 0.9775 - val_loss: 0.0756 - val_f1_score: 0.9771\n",
      "Epoch 12/100\n",
      "3424/3424 [==============================] - 33s 10ms/sample - loss: 0.0694 - f1_score: 0.9786 - val_loss: 0.0725 - val_f1_score: 0.9780\n",
      "Epoch 13/100\n",
      "3424/3424 [==============================] - 36s 10ms/sample - loss: 0.0654 - f1_score: 0.9797 - val_loss: 0.0712 - val_f1_score: 0.9780\n",
      "Epoch 14/100\n",
      "3424/3424 [==============================] - 34s 10ms/sample - loss: 0.0620 - f1_score: 0.9804 - val_loss: 0.0687 - val_f1_score: 0.9786\n",
      "Epoch 15/100\n",
      "3424/3424 [==============================] - 36s 11ms/sample - loss: 0.0596 - f1_score: 0.9813 - val_loss: 0.0679 - val_f1_score: 0.9791\n",
      "Epoch 16/100\n",
      "3424/3424 [==============================] - 35s 10ms/sample - loss: 0.0570 - f1_score: 0.9820 - val_loss: 0.0680 - val_f1_score: 0.9794\n",
      "Epoch 17/100\n",
      "3424/3424 [==============================] - 36s 11ms/sample - loss: 0.0542 - f1_score: 0.9829 - val_loss: 0.0650 - val_f1_score: 0.9798\n",
      "Epoch 18/100\n",
      "3424/3424 [==============================] - 35s 10ms/sample - loss: 0.0518 - f1_score: 0.9832 - val_loss: 0.0633 - val_f1_score: 0.9801\n",
      "Epoch 19/100\n",
      "3424/3424 [==============================] - 37s 11ms/sample - loss: 0.0500 - f1_score: 0.9840 - val_loss: 0.0642 - val_f1_score: 0.9808\n",
      "Epoch 20/100\n",
      "3424/3424 [==============================] - 34s 10ms/sample - loss: 0.0484 - f1_score: 0.9844 - val_loss: 0.0634 - val_f1_score: 0.9808\n",
      "Epoch 21/100\n",
      "3424/3424 [==============================] - 36s 10ms/sample - loss: 0.0465 - f1_score: 0.9849 - val_loss: 0.0651 - val_f1_score: 0.9804\n",
      "Epoch 22/100\n",
      "3424/3424 [==============================] - 37s 11ms/sample - loss: 0.0443 - f1_score: 0.9858 - val_loss: 0.0616 - val_f1_score: 0.9806\n",
      "Epoch 23/100\n",
      "3424/3424 [==============================] - 39s 11ms/sample - loss: 0.0425 - f1_score: 0.9862 - val_loss: 0.0631 - val_f1_score: 0.9805\n",
      "Epoch 24/100\n",
      "3424/3424 [==============================] - 40s 12ms/sample - loss: 0.0416 - f1_score: 0.9865 - val_loss: 0.0621 - val_f1_score: 0.9811\n",
      "Epoch 25/100\n",
      "3424/3424 [==============================] - 37s 11ms/sample - loss: 0.0395 - f1_score: 0.9872 - val_loss: 0.0619 - val_f1_score: 0.9807\n",
      "Epoch 26/100\n",
      "3424/3424 [==============================] - 37s 11ms/sample - loss: 0.0389 - f1_score: 0.9873 - val_loss: 0.0611 - val_f1_score: 0.9813\n",
      "Epoch 27/100\n",
      "3424/3424 [==============================] - 36s 10ms/sample - loss: 0.0377 - f1_score: 0.9876 - val_loss: 0.0616 - val_f1_score: 0.9808\n",
      "Epoch 28/100\n",
      "3424/3424 [==============================] - 37s 11ms/sample - loss: 0.0356 - f1_score: 0.9884 - val_loss: 0.0630 - val_f1_score: 0.9806\n",
      "Epoch 29/100\n",
      "3424/3424 [==============================] - 36s 10ms/sample - loss: 0.0345 - f1_score: 0.9889 - val_loss: 0.0631 - val_f1_score: 0.9806\n",
      "Epoch 30/100\n",
      "3424/3424 [==============================] - 36s 11ms/sample - loss: 0.0335 - f1_score: 0.9892 - val_loss: 0.0641 - val_f1_score: 0.9812\n",
      "Epoch 31/100\n",
      "3424/3424 [==============================] - 33s 10ms/sample - loss: 0.0316 - f1_score: 0.9897 - val_loss: 0.0614 - val_f1_score: 0.9812\n",
      "Epoch 32/100\n",
      "3424/3424 [==============================] - 33s 10ms/sample - loss: 0.0306 - f1_score: 0.9899 - val_loss: 0.0631 - val_f1_score: 0.9816\n",
      "Epoch 33/100\n",
      "3424/3424 [==============================] - 33s 10ms/sample - loss: 0.0297 - f1_score: 0.9904 - val_loss: 0.0632 - val_f1_score: 0.9821\n",
      "Epoch 34/100\n",
      "3424/3424 [==============================] - 34s 10ms/sample - loss: 0.0296 - f1_score: 0.9903 - val_loss: 0.0626 - val_f1_score: 0.9814\n",
      "Epoch 35/100\n",
      "3424/3424 [==============================] - 33s 10ms/sample - loss: 0.0291 - f1_score: 0.9903 - val_loss: 0.0649 - val_f1_score: 0.9817\n",
      "Epoch 36/100\n",
      "3424/3424 [==============================] - 35s 10ms/sample - loss: 0.0271 - f1_score: 0.9911 - val_loss: 0.0650 - val_f1_score: 0.9815\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=10, )\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, np.array(y_train),\n",
    "    validation_data=(x_val, np.array(y_val)),\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9808242506811989\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "actuals = []\n",
    "\n",
    "for i, xt in enumerate(x_val):\n",
    "    p = model.predict(np.array([xt]))\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    y_true = np.argmax(np.array(y_val), axis=-1)[i]\n",
    "    \n",
    "    for true, pred in zip(y_true, p[0]):\n",
    "        actuals.append(true)\n",
    "        preds.append(pred)\n",
    "        \n",
    "print(f1_score(preds, actuals, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9240677051722976\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "actuals = []\n",
    "\n",
    "for i, xt in enumerate(x_val):\n",
    "    p = model.predict(np.array([xt]))\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    y_true = np.argmax(np.array(y_val), axis=-1)[i]\n",
    "    \n",
    "    if 13030 in list(xt):\n",
    "        first_pad_idx = list(xt).index(13030)\n",
    "        _zip = zip(y_true[:first_pad_idx], p[0][:first_pad_idx])\n",
    "    else:\n",
    "        _zip = zip(y_true, p[0])\n",
    "    \n",
    "    for true, pred in _zip:\n",
    "        actuals.append(true)\n",
    "        preds.append(pred)\n",
    "\n",
    "print(f1_score(preds, actuals, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
