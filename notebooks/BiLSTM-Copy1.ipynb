{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Flatten, Dense, TimeDistributed, \\\n",
    "    SpatialDropout1D, Bidirectional, Conv1D, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrixMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super(ConfusionMatrixMetric,self).__init__(name='confusion_matrix_metric',**kwargs)\n",
    "        self.num_classes=num_classes\n",
    "        self.f1_score_micro = self.add_weight(\"total\", shape=(num_classes, num_classes), initializer=\"zeros\")\n",
    "        \n",
    "    def reset_states(self):\n",
    "        for s in self.variables:\n",
    "            s.assign(tf.zeros(shape=s.shape))\n",
    "            \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.f1_score_micro.assign_add(self.compute_f1_score_micro(y_true, y_pred))\n",
    "        return self.f1_score_micro\n",
    "        \n",
    "    def result(self):\n",
    "        return self.process_f1_score_micro()\n",
    "    \n",
    "    def compute_f1_score_micro(self, y_true, y_pred):\n",
    "        y_true = np.argmax(y_true.numpy(), axis=-1).reshape(-1)\n",
    "        y_pred = np.argmax(y_pred.numpy(), axis=-1).reshape(-1)\n",
    "        \n",
    "        o_pad_idx = np.where(y_true==20)\n",
    "        \n",
    "        y_true = np.delete(y_true, o_pad_idx)\n",
    "        y_pred = np.delete(y_pred, o_pad_idx)\n",
    "  \n",
    "        f1s = f1_score(y_true, y_pred, average='micro')\n",
    "        \n",
    "        print(f1s)\n",
    "        \n",
    "        return f1s\n",
    "    \n",
    "    def process_f1_score_micro(self):\n",
    "        return self.f1_score_micro\n",
    "    \n",
    "    def fill_output(self,output):\n",
    "        results = self.result()\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqModel(tf.keras.Sequential):\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)\n",
    "            loss = self.compiled_loss(\n",
    "                y,\n",
    "                y_pred,\n",
    "                regularization_losses=self.losses,\n",
    "            )\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        output={m.name: m.result() for m in self.metrics[:-1]}\n",
    "        \n",
    "        if 'confusion_matrix_metric' in self.metrics_names:\n",
    "            self.metrics[-1].fill_output(output)\n",
    "\n",
    "        return output\n",
    "        \n",
    "        \n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "\n",
    "        y_pred = self(x, training=False)\n",
    "        loss = self.compiled_loss(\n",
    "            y,\n",
    "            y_pred,\n",
    "            regularization_losses=self.losses,\n",
    "        )\n",
    "\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        output={m.name: m.result() for m in self.metrics[:-1]}\n",
    "        \n",
    "        if 'confusion_matrix_metric' in self.metrics_names:\n",
    "            self.metrics[-1].fill_output(output)    \n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pengamat</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politik</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dari</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Universitas</td>\n",
       "      <td>B-ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gadjah</td>\n",
       "      <td>I-ORGANIZATION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word             tag\n",
       "0     Pengamat               O\n",
       "1      politik               O\n",
       "2         dari               O\n",
       "3  Universitas  B-ORGANIZATION\n",
       "4       Gadjah  I-ORGANIZATION"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>sentence #</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pengamat</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politik</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dari</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Universitas</td>\n",
       "      <td>B-ORGANIZATION</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gadjah</td>\n",
       "      <td>I-ORGANIZATION</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word             tag  sentence #\n",
       "0     Pengamat               O           1\n",
       "1      politik               O           1\n",
       "2         dari               O           1\n",
       "3  Universitas  B-ORGANIZATION           1\n",
       "4       Gadjah  I-ORGANIZATION           1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "cnt = 1\n",
    "\n",
    "for i in df.itertuples():\n",
    "    sentences.append(cnt)\n",
    "    \n",
    "    if '.' in str(i.word):\n",
    "        cnt += 1\n",
    "        \n",
    "df['sentence #'] = sentences\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func = lambda s: [(w, t) for w, t in zip(s['word'].values.tolist(), s['tag'].values.tolist())]\n",
    "grouped = df.groupby('sentence #').apply(agg_func)\n",
    "sentences = [s for s in grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(df['word'].values))\n",
    "words.append('PADDING')\n",
    "num_words = len(words)\n",
    "tags = list(set(df['tag'].values))\n",
    "num_tags = len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate([tag for tag in tags if tag != 'O'])}\n",
    "tag2idx['O'] = len(tags)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L-ORGANIZATION': 0,\n",
       " 'I-TIME': 1,\n",
       " 'U-ORGANIZATION': 2,\n",
       " 'L-LOCATION': 3,\n",
       " 'U-PERSON': 4,\n",
       " 'I-LOCATION': 5,\n",
       " 'U-LOCATION': 6,\n",
       " 'U-TIME': 7,\n",
       " 'U-QUANTITY': 8,\n",
       " 'L-QUANTITY': 9,\n",
       " 'B-LOCATION': 10,\n",
       " 'B-TIME': 11,\n",
       " 'I-QUANTITY': 12,\n",
       " 'L-PERSON': 13,\n",
       " 'I-PERSON': 14,\n",
       " 'I-ORGANIZATION': 15,\n",
       " 'B-ORGANIZATION': 16,\n",
       " 'L-TIME': 17,\n",
       " 'B-QUANTITY': 18,\n",
       " 'B-PERSON': 19,\n",
       " 'O': 20}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13031"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 60\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding='post', value=num_words-1)\n",
    "\n",
    "y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding='post', value=tag2idx['O'])\n",
    "y = [to_categorical(i, num_classes=num_tags) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4892, 60, 21)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2319,   574,  1942,  4847,  5615,  2764, 12565,  2384,  1880,\n",
       "       12565,  5882, 12565,  7341,  8932,  1785,  6126,  1397, 10136,\n",
       "        4265,  1527, 11466,  7710,  7514,  8643,  2595,  9699, 12853,\n",
       "        5469,  7959, 13030, 13030, 13030, 13030, 13030, 13030, 13030,\n",
       "       13030, 13030, 13030, 13030, 13030, 13030, 13030, 13030, 13030,\n",
       "       13030, 13030, 13030, 13030, 13030, 13030, 13030, 13030, 13030,\n",
       "       13030, 13030, 13030, 13030, 13030, 13030], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-23f199ad2330>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'arr' is not defined"
     ]
    }
   ],
   "source": [
    "len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "64*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1b8d7e787d63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'arr' is not defined"
     ]
    }
   ],
   "source": [
    "len(arr.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 60)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({20: 3554,\n",
       "         16: 13,\n",
       "         15: 21,\n",
       "         0: 13,\n",
       "         19: 23,\n",
       "         13: 23,\n",
       "         4: 26,\n",
       "         2: 15,\n",
       "         11: 6,\n",
       "         1: 33,\n",
       "         17: 6,\n",
       "         6: 11,\n",
       "         10: 6,\n",
       "         5: 14,\n",
       "         3: 6,\n",
       "         14: 50,\n",
       "         18: 10,\n",
       "         9: 10})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.argmax(y[:64], axis=-1)\n",
    "print(arr.shape)\n",
    "Counter(arr.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    1,    2, ..., 3837, 3838, 3839]),)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.where(arr.reshape(-1)==20)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 15,  0, 19, 13, 16,  0, 19, 13,  4,  2,  4,  4,  2,  2,  4, 11,\n",
       "        1,  1,  1,  1,  1,  1, 17,  4,  4,  2, 16, 15, 15,  0, 19, 13, 19,\n",
       "       13,  4,  4,  6,  4,  4,  4,  4,  4,  4,  4,  2, 16, 15,  0,  4,  2,\n",
       "        4,  2, 19, 13, 19, 13,  4, 19, 13, 10,  5,  5,  5,  5,  3, 11,  1,\n",
       "        1,  1,  1,  1,  1, 17,  6, 19, 13, 16, 15,  0,  6, 19, 14, 14, 13,\n",
       "       16,  0,  4,  6,  4, 16, 15, 15, 15, 15, 15, 15,  0, 10,  5,  5,  3,\n",
       "       18,  9,  6, 19, 14, 13,  6, 19, 13,  6, 19, 14, 13,  6, 19, 13,  6,\n",
       "       19, 14, 13, 16,  0, 19, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 13,\n",
       "       10,  3,  2, 16,  0, 19, 13,  6, 11,  1,  1,  1,  1,  1,  1, 17, 16,\n",
       "       15, 15, 15, 15, 15,  0, 16, 15,  0, 18,  9, 19, 14, 14, 14, 14, 14,\n",
       "       14, 14, 14, 13, 18,  9, 19, 14, 14, 14, 14, 14, 14, 14, 14, 14, 13,\n",
       "       18,  9, 19, 14, 14, 14, 14, 14, 13, 18,  9, 19, 14, 14, 14, 14, 14,\n",
       "       14, 14, 14, 14, 14, 14, 14, 13, 18,  9,  4,  6,  2,  4,  4,  2,  4,\n",
       "       19, 14, 13, 16,  0,  2,  4,  2, 19, 13,  4, 10,  5,  5,  5,  3, 11,\n",
       "        1,  1,  1,  1,  1,  1, 17, 16, 15, 15, 15, 15,  0,  2, 19, 13,  2,\n",
       "       10,  5,  5,  3, 10,  5,  5,  5,  3, 11,  1,  1,  1,  1,  1,  1, 17,\n",
       "        2, 18,  9, 18,  9, 18,  9, 11,  1,  1,  1, 17, 18,  9])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.delete(arr.reshape(-1), idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.delete(arr, idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"seq_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 60, 400)           5212400   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 60, 400)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 60, 200)           400800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 60, 21)            4221      \n",
      "=================================================================\n",
      "Total params: 5,617,421\n",
      "Trainable params: 5,617,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = SeqModel([\n",
    "    Input(shape=(max_len, )),\n",
    "    Embedding(\n",
    "        input_dim=num_words,\n",
    "        output_dim=400,\n",
    "        input_length=max_len,\n",
    "    ),\n",
    "    SpatialDropout1D(0.1),\n",
    "    Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1)),\n",
    "    Dense(num_tags, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrixMetric(tf.keras.metrics.Metric):\n",
    "    \"\"\"\n",
    "    A custom Keras metric to compute the running average of the confusion matrix\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super(ConfusionMatrixMetric,self).__init__(name='confusion_matrix_metric',**kwargs) # handles base args (e.g., dtype)\n",
    "        self.num_classes=num_classes\n",
    "        self.total_cm = self.add_weight(\"total\", shape=(num_classes,num_classes), initializer=\"zeros\")\n",
    "        \n",
    "    def reset_states(self):\n",
    "        for s in self.variables:\n",
    "            s.assign(tf.zeros(shape=s.shape))\n",
    "            \n",
    "    def update_state(self, y_true, y_pred,sample_weight=None):\n",
    "        self.total_cm.assign_add(self.confusion_matrix(y_true,y_pred))\n",
    "        return self.total_cm\n",
    "        \n",
    "    def result(self):\n",
    "        return self.process_confusion_matrix()\n",
    "    \n",
    "    def confusion_matrix(self,y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Make a confusion matrix\n",
    "        \"\"\"\n",
    "        y_pred=tf.argmax(y_pred,1)\n",
    "        cm=tf.math.confusion_matrix(y_true,y_pred,dtype=tf.float32,num_classes=self.num_classes)\n",
    "        return cm\n",
    "    \n",
    "    def process_confusion_matrix(self):\n",
    "        \"returns precision, recall and f1 along with overall accuracy\"\n",
    "        cm=self.total_cm\n",
    "        diag_part=tf.linalg.diag_part(cm)\n",
    "        precision=diag_part/(tf.reduce_sum(cm,0)+tf.constant(1e-15))\n",
    "        recall=diag_part/(tf.reduce_sum(cm,1)+tf.constant(1e-15))\n",
    "        f1=2*precision*recall/(precision+recall+tf.constant(1e-15))\n",
    "        return precision,recall,f1\n",
    "    \n",
    "    def fill_output(self,output):\n",
    "        results=self.result()\n",
    "        for i in range(self.num_classes):\n",
    "            output['precision_{}'.format(i)]=results[0][i]\n",
    "            output['recall_{}'.format(i)]=results[1][i]\n",
    "            output['F1_{}'.format(i)]=results[2][i]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryTruePositives(tf.keras.metrics.Metric):\n",
    "\n",
    "  def __init__(self, name='binary_true_positives', **kwargs):\n",
    "    super(BinaryTruePositives, self).__init__(name=name, **kwargs)\n",
    "    self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "\n",
    "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "    y_true = tf.cast(y_true, tf.bool)\n",
    "    y_pred = tf.cast(y_pred, tf.bool)\n",
    "\n",
    "    values = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))\n",
    "    values = tf.cast(values, self.dtype)\n",
    "    if sample_weight is not None:\n",
    "      sample_weight = tf.cast(sample_weight, self.dtype)\n",
    "      values = tf.multiply(values, sample_weight)\n",
    "    self.true_positives.assign_add(tf.reduce_sum(values))\n",
    "\n",
    "  def result(self):\n",
    "    return self.true_positives\n",
    "\n",
    "  def reset_states(self):\n",
    "    self.true_positives.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1ScoreMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score_metric', **kwargs):\n",
    "        super(F1ScoreMetric, self).__init__(name=name, **kwargs)\n",
    "        self.f1_score_micro = self.add_weight(name='f1_score_metric', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = np.argmax(y_true.numpy(), axis=-1).reshape(-1)\n",
    "        y_pred = np.argmax(y_pred.numpy(), axis=-1).reshape(-1)\n",
    "\n",
    "        o_pad_idx = np.where(y_true==20)\n",
    "\n",
    "        y_true = np.delete(y_true, o_pad_idx)\n",
    "        y_pred = np.delete(y_pred, o_pad_idx)\n",
    "\n",
    "        score = f1_score(y_true, y_pred, average='micro')\n",
    "        self.f1_score_micro.assign_add(score)\n",
    "\n",
    "    def result(self):\n",
    "        return self.f1_score_micro\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.f1_score_micro.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-4931a0c55a3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF1ScoreMetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Intermediate result:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ner/lib/python3.7/site-packages/tensorflow/python/keras/utils/metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_context_for_symbolic_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# update_op will be None in eager execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0mmetric_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-2036988f39c4>\u001b[0m in \u001b[0;36mupdate_state\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "m = F1ScoreMetric()\n",
    "m.update_state([0, 1, 1, 1], [0, 1, 0, 0])\n",
    "print('Intermediate result:', float(m.result()))\n",
    "\n",
    "m.update_state([1, 1, 1, 1], [0, 1, 1, 0])\n",
    "print('Final result:', float(m.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class F1ScoreMetric(tf.keras.metrics.Metric):\n",
    "#     def __init__(self, num_classes, **kwargs):\n",
    "#         super(ConfusionMatrixMetric,self).__init__(name='f1_score_metric', **kwargs)\n",
    "#         self.num_classes=num_classes\n",
    "#         self.total_cm = self.add_weight(\"total\", shape=(num_classes,num_classes), initializer=\"zeros\")\n",
    "        \n",
    "#     def reset_states(self):\n",
    "#         for s in self.variables:\n",
    "#             s.assign(tf.zeros(shape=s.shape))\n",
    "            \n",
    "#     def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "#         self.total_cm.assign_add(self.f1_score_micro(y_true,y_pred))\n",
    "#         return self.total_cm\n",
    "    \n",
    "#     def result(self):\n",
    "#         return self.process_confusion_matrix()\n",
    "    \n",
    "#     def f1_score_micro(self, y_true, y_pred):\n",
    "#         y_true = np.argmax(y_true.numpy(), axis=-1).reshape(-1)\n",
    "#         y_pred = np.argmax(y_pred.numpy(), axis=-1).reshape(-1)\n",
    "\n",
    "#         o_pad_idx = np.where(y_true==20)\n",
    "\n",
    "#         y_true = np.delete(y_true, o_pad_idx)\n",
    "#         y_pred = np.delete(y_pred, o_pad_idx)\n",
    "\n",
    "#         score = f1_score(y_true, y_pred, average='micro')\n",
    "\n",
    "#         return score\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 60, 400)      5212400     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 60, 400)      0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 60, 128)      102528      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 60, 128)      204928      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 60, 128)      307328      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 60, 128)      409728      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 60, 128)      512128      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 60, 640)      0           conv1d_5[0][0]                   \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 60, 200)      592800      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 60, 21)       4221        bidirectional_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 7,346,061\n",
      "Trainable params: 7,346,061\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_sequence = Input(shape=(max_len, ))\n",
    "model = Embedding(\n",
    "        input_dim=num_words,\n",
    "        output_dim=400,\n",
    "        input_length=max_len,\n",
    ")(input_sequence)\n",
    "model = SpatialDropout1D(0.5)(model)\n",
    "model2g = Conv1D(128, 2, activation='relu', padding='same')(model)\n",
    "model4g = Conv1D(128, 4, activation='relu', padding='same')(model)\n",
    "model6g = Conv1D(128, 6, activation='relu', padding='same')(model)\n",
    "model8g = Conv1D(128, 8, activation='relu', padding='same')(model)\n",
    "model10g = Conv1D(128, 10, activation='relu', padding='same')(model)\n",
    "model = concatenate([model2g, model4g, model6g, model8g, model10g])\n",
    "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.5))(model)\n",
    "output_sequence = Dense(num_tags, activation='softmax')(model)\n",
    "model = Model(input_sequence, output_sequence)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_micro_metric(y_true, y_pred):\n",
    "    y_true = np.argmax(y_true.numpy(), axis=-1).reshape(-1)\n",
    "    y_pred = np.argmax(y_pred.numpy(), axis=-1).reshape(-1)\n",
    "\n",
    "    o_pad_idx = np.where(y_true==20)\n",
    "\n",
    "    y_true = np.delete(y_true, o_pad_idx)\n",
    "    y_pred = np.delete(y_pred, o_pad_idx)\n",
    "\n",
    "    score = f1_score(y_true, y_pred, average='micro')\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "model.compile(\n",
    "    loss=loss, \n",
    "    optimizer=optimizer, \n",
    "    metrics=[f1_micro_metric],\n",
    "    run_eagerly=True,\n",
    "    experimental_run_tf_function=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4/54 [=>............................] - ETA: 47s - loss: 1.8398 - f1_micro_metric: 0.0070"
     ]
    }
   ],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(patience=10, monitor='f1_micro_metric', mode='max')\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, np.array(y_train),\n",
    "    validation_data=(x_val, np.array(y_val)),\n",
    "    epochs=1, verbose=1, callbacks=[es], batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.07117744535207748], 'val_loss': [0.11728736758232117]}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
