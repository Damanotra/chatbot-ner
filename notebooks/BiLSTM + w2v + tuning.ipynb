{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import talos as ta\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Flatten, Dense, TimeDistributed, \\\n",
    "    SpatialDropout1D, Bidirectional, Conv1D, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrixMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super(ConfusionMatrixMetric,self).__init__(name='confusion_matrix_metric',**kwargs)\n",
    "        self.num_classes=num_classes\n",
    "        self.total_cm = self.add_weight(\"total\", shape=(num_classes,num_classes), initializer=\"zeros\")\n",
    "        \n",
    "    def reset_states(self):\n",
    "        for s in self.variables:\n",
    "            s.assign(tf.zeros(shape=s.shape))\n",
    "            \n",
    "    def update_state(self, y_true, y_pred,sample_weight=None):\n",
    "        self.total_cm.assign_add(self.confusion_matrix(y_true,y_pred))\n",
    "        return self.total_cm\n",
    "        \n",
    "    def result(self):\n",
    "        return self.process_confusion_matrix()\n",
    "    \n",
    "    def confusion_matrix(self,y_true, y_pred):\n",
    "        y_pred = tf.argmax(y_pred, axis=2)\n",
    "        y_true = tf.argmax(y_true, axis=2)\n",
    "\n",
    "        y_pred = tf.reshape(y_pred, [-1])\n",
    "        y_true = tf.reshape(y_true, [-1])\n",
    "  \n",
    "        cm = tf.math.confusion_matrix(\n",
    "            y_true, \n",
    "            y_pred, \n",
    "            dtype=tf.float32, \n",
    "            num_classes=self.num_classes\n",
    "        )\n",
    "        \n",
    "        return cm\n",
    "    \n",
    "    def process_confusion_matrix(self):\n",
    "        cm = self.total_cm\n",
    "        diag_part=tf.linalg.diag_part(cm)\n",
    "        precision=diag_part/(tf.reduce_sum(cm,0)+tf.constant(1e-15))\n",
    "        recall=diag_part/(tf.reduce_sum(cm,1)+tf.constant(1e-15))\n",
    "        f1=2*precision*recall/(precision+recall+tf.constant(1e-15))\n",
    "        return precision, recall, f1\n",
    "    \n",
    "    def fill_output(self,output):\n",
    "        results=self.result()\n",
    "        for i in range(self.num_classes):\n",
    "            output['precision_{}'.format(i)]=results[0][i]\n",
    "            output['recall_{}'.format(i)]=results[1][i]\n",
    "            output['f1_{}'.format(i)]=results[2][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqModel(tf.keras.Sequential):\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)\n",
    "            loss = self.compiled_loss(\n",
    "                y,\n",
    "                y_pred,\n",
    "                regularization_losses=self.losses,\n",
    "            )\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        output={m.name: m.result() for m in self.metrics[:-1]}\n",
    "        \n",
    "        if 'confusion_matrix_metric' in self.metrics_names:\n",
    "            self.metrics[-1].fill_output(output)\n",
    "\n",
    "        return output\n",
    "        \n",
    "        \n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "\n",
    "        y_pred = self(x, training=False)\n",
    "        loss = self.compiled_loss(\n",
    "            y,\n",
    "            y_pred,\n",
    "            regularization_losses=self.losses,\n",
    "        )\n",
    "\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        output={m.name: m.result() for m in self.metrics[:-1]}\n",
    "        \n",
    "        if 'confusion_matrix_metric' in self.metrics_names:\n",
    "            self.metrics[-1].fill_output(output)    \n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pengamat</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politik</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dari</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Universitas</td>\n",
       "      <td>B-ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gadjah</td>\n",
       "      <td>I-ORGANIZATION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word             tag\n",
       "0     Pengamat               O\n",
       "1      politik               O\n",
       "2         dari               O\n",
       "3  Universitas  B-ORGANIZATION\n",
       "4       Gadjah  I-ORGANIZATION"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>sentence #</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pengamat</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politik</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dari</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Universitas</td>\n",
       "      <td>B-ORGANIZATION</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gadjah</td>\n",
       "      <td>I-ORGANIZATION</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word             tag  sentence #\n",
       "0     Pengamat               O           1\n",
       "1      politik               O           1\n",
       "2         dari               O           1\n",
       "3  Universitas  B-ORGANIZATION           1\n",
       "4       Gadjah  I-ORGANIZATION           1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "cnt = 1\n",
    "\n",
    "for i in df.itertuples():\n",
    "    sentences.append(cnt)\n",
    "    \n",
    "    if '.' in str(i.word):\n",
    "        cnt += 1\n",
    "        \n",
    "df['sentence #'] = sentences\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func = lambda s: [(w, t) for w, t in zip(s['word'].values.tolist(), s['tag'].values.tolist())]\n",
    "grouped = df.groupby('sentence #').apply(agg_func)\n",
    "sentences = [s for s in grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(df['word'].values))\n",
    "words.append('PADDING')\n",
    "num_words = len(words)\n",
    "tags = list(set(df['tag'].values))\n",
    "num_tags = len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate([tag for tag in tags if tag != 'O'])}\n",
    "tag2idx['O'] = len(tags)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L-TIME': 0,\n",
       " 'L-PERSON': 1,\n",
       " 'L-QUANTITY': 2,\n",
       " 'I-QUANTITY': 3,\n",
       " 'B-LOCATION': 4,\n",
       " 'L-ORGANIZATION': 5,\n",
       " 'U-PERSON': 6,\n",
       " 'U-ORGANIZATION': 7,\n",
       " 'I-LOCATION': 8,\n",
       " 'B-TIME': 9,\n",
       " 'I-PERSON': 10,\n",
       " 'B-QUANTITY': 11,\n",
       " 'U-TIME': 12,\n",
       " 'U-QUANTITY': 13,\n",
       " 'B-ORGANIZATION': 14,\n",
       " 'B-PERSON': 15,\n",
       " 'L-LOCATION': 16,\n",
       " 'U-LOCATION': 17,\n",
       " 'I-TIME': 18,\n",
       " 'I-ORGANIZATION': 19,\n",
       " 'O': 20}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13031"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 60\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding='post', value=num_words-1)\n",
    "\n",
    "y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding='post', value=tag2idx['O'])\n",
    "y = [to_categorical(i, num_classes=num_tags) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4892, 60, 21)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load(\"../checkpoint/w2vec_wiki_id_case\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(words), 400))\n",
    "\n",
    "for i, w in enumerate(words):\n",
    "    try:\n",
    "        embedding_vector = model.wv[w]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except:\n",
    "        embedding_matrix[i] = np.random.normal(0, np.sqrt(0.25), 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'optimizer': ['Adam'],\n",
    "    'lr': [0.01],\n",
    "    'units': [50],\n",
    "    'dim': [300],\n",
    "    'dropout': [0.5],\n",
    "    'batch_size': [64]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(x_train, y_train, x_val, y_val, params):\n",
    "    model = SeqModel([\n",
    "        Input(shape=(max_len, )),\n",
    "        Embedding(\n",
    "            input_dim= embedding_matrix.shape[0], \n",
    "            weights=[embedding_matrix], \n",
    "            output_dim=embedding_matrix.shape[1], \n",
    "            input_length=params['dim'],\n",
    "            trainable=False\n",
    "        ),\n",
    "        SpatialDropout1D(params['dropout']),\n",
    "        Bidirectional(LSTM(units=params['units'], return_sequences=True, recurrent_dropout=params['dropout'])),\n",
    "        Dense(num_tags, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    f1_score_m = tfa.metrics.F1Score(\n",
    "        num_classes=num_tags,\n",
    "        average='micro',\n",
    "        name='f1_score',\n",
    "        threshold=0.5\n",
    "    )\n",
    "    optm = tf.keras.optimizers.Adam(lr=params['lr'])\n",
    "        \n",
    "    if params['optimizer'] == 'RMSprop':\n",
    "        optm = tf.keras.optimizers.RMSprop(lr=params['lr'])\n",
    "    \n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "        optimizer=optm,\n",
    "        metrics=[f1_score_m, ConfusionMatrixMetric(num_tags)]\n",
    "    )\n",
    "    \n",
    "    es = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train, np.array(y_train),\n",
    "        validation_data=(x_val, np.array(y_val)),\n",
    "        epochs=100, verbose=3, callbacks=[es], batch_size=params['batch_size']\n",
    "    )\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 1/4 [05:41<17:04, 341.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 2/4 [11:26<11:24, 342.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 3/4 [16:32<05:31, 331.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [22:40<00:00, 340.22s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "t = ta.Scan(x=x_train,\n",
    "            y=np.array(y_train),\n",
    "            model=create_model,\n",
    "            params=params,\n",
    "            experiment_name='bilstm_w2v_opt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_f1_score</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054178</td>\n",
       "      <td>0.982069</td>\n",
       "      <td>0.072648</td>\n",
       "      <td>0.979905</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.049939</td>\n",
       "      <td>0.983058</td>\n",
       "      <td>0.072273</td>\n",
       "      <td>0.980170</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.050112</td>\n",
       "      <td>0.983478</td>\n",
       "      <td>0.074053</td>\n",
       "      <td>0.978351</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.054957</td>\n",
       "      <td>0.982108</td>\n",
       "      <td>0.070858</td>\n",
       "      <td>0.979230</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  f1_score  val_loss  val_f1_score  batch_size\n",
       "0  0.054178  0.982069  0.072648      0.979905          32\n",
       "1  0.049939  0.983058  0.072273      0.980170          64\n",
       "2  0.050112  0.983478  0.074053      0.978351         128\n",
       "3  0.054957  0.982108  0.070858      0.979230         256"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.data[['loss', 'f1_score', 'val_loss', 'val_f1_score', 'batch_size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "experiment_name          bilstm_w2v_opt\n",
       "random_method          uniform_mersenne\n",
       "reduction_method                   None\n",
       "reduction_interval                   50\n",
       "reduction_window                     20\n",
       "reduction_threshold                 0.2\n",
       "reduction_metric                val_acc\n",
       "complete_time            09/03/20/20:56\n",
       "x_shape                      (4158, 60)\n",
       "y_shape                  (4158, 60, 21)\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
